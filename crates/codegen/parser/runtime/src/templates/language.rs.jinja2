// This file is generated; we can't reasonably satisfy some of these lints.
#![allow(
    clippy::if_not_else,
    clippy::too_many_lines,
    clippy::unused_self,
    clippy::struct_excessive_bools,
    clippy::similar_names
)]

use semver::Version;
#[cfg(feature = "slang_napi_interfaces")]
use napi_derive::napi;

use crate::cst;
pub use crate::kinds::LexicalContext;
use crate::kinds::{IsLexicalContext, LexicalContextType, RuleKind, TokenKind};
use crate::lexer::{KeywordScan, Lexer};
#[cfg(feature = "slang_napi_interfaces")]
use crate::napi::napi_parse_output::ParseOutput as NAPIParseOutput;
use crate::parse_output::ParseOutput;
use crate::support::{
    ChoiceHelper, OneOrMoreHelper, OptionalHelper, ParserContext, ParserFunction, ParserResult,
    PrecedenceHelper, RecoverFromNoMatch, SeparatedHelper, SequenceHelper, ZeroOrMoreHelper,
};

#[derive(Debug)]
#[cfg_attr(feature = "slang_napi_interfaces", napi(namespace = "language"))]
pub struct Language {
    pub(crate) version: Version,
    {%- for version in code.referenced_versions -%}
        pub(crate) version_is_at_least_{{ version | replace(from=".", to="_") }}: bool,
    {%- endfor -%}
}

#[derive(thiserror::Error, Debug)]
pub enum Error {
    #[error("Unsupported {{ language_name }} language version '{0}'.")]
    UnsupportedLanguageVersion(Version),

    #[cfg(feature = "slang_napi_interfaces")]
    #[error("Invalid semantic version '{0}'.")]
    InvalidSemanticVersion(String),
}

#[cfg(feature = "slang_napi_interfaces")]
impl From<Error> for napi::Error {
    fn from(value: Error) -> Self {
        napi::Error::from_reason(value.to_string())
    }
}

impl Language {
    pub const SUPPORTED_VERSIONS: &[Version] = &[
        {% for version in versions %}
            Version::new({{ version | split(pat=".") | join(sep=", ") }}),
        {% endfor %}
    ];

    pub fn new(version: Version) -> std::result::Result<Self, Error> {
        if Self::SUPPORTED_VERSIONS.binary_search(&version).is_ok() {
            Ok(Self {
                {%- for version in code.referenced_versions %}
                    version_is_at_least_{{ version | replace(from=".", to="_") }}: Version::new({{ version | split(pat=".") | join(sep=", ") }}) <= version,
                {%- endfor -%}
                version,
            })
        } else {
            Err(Error::UnsupportedLanguageVersion(version))
        }
    }

    pub fn version(&self) -> &Version {
        &self.version
    }

    /********************************************
     *         Parser Functions
     ********************************************/

    {% for parser_name, parser_code in code.parser_functions %}
        #[allow(unused_assignments, unused_parens)]
        fn {{ parser_name | snake_case }}(&self, input: &mut ParserContext<'_>) -> ParserResult { {{ parser_code }} }
    {% endfor %}

    /********************************************
     *         Scanner Functions
     ********************************************/

    {% for scanner_name, scanner_code in code.scanner_functions %}
        #[allow(unused_assignments, unused_parens)]
        fn {{ scanner_name | snake_case }}(&self, input: &mut ParserContext<'_>) -> bool { {{ scanner_code }} }
    {% endfor %}

    // Keyword scanners
    {%- for keyword_name, code in code.keyword_compound_scanners %}
        {# #[allow(clippy::ifs_same_cond, clippy::eq_op, clippy::nonminimal_bool, clippy::overly_complex_bool_expr)] #}
        #[inline]
        fn {{ keyword_name | snake_case }}(&self, input: &mut ParserContext<'_>, ident: &str) -> KeywordScan { {{ code }} }
    {%- endfor %}

    pub fn scan(&self, lexical_context: LexicalContext, input: &str) -> Vec<TokenKind> {
        let mut input = ParserContext::new(input);
        match lexical_context {
            {%- for context_name, context in code.scanner_contexts -%}
                LexicalContext::{{ context_name }} =>
                    Lexer::next_token::<LexicalContextType::{{ context_name }}>(self, &mut input),
            {%- endfor -%}
        }
    }

    pub fn parse(&self, kind: RuleKind, input: &str) -> ParseOutput {
        match kind {
            {%- for parser_name, _code in code.parser_functions -%}
                RuleKind::{{ parser_name }} => Self::{{ parser_name | snake_case }}.parse(self, input),
            {%- endfor -%}
        }
    }
}

impl Lexer for Language {
    fn leading_trivia(&self, input: &mut ParserContext<'_>) -> ParserResult {
        Language::leading_trivia(self, input)
    }

    fn trailing_trivia(&self, input: &mut ParserContext<'_>) -> ParserResult {
        Language::trailing_trivia(self, input)
    }

    fn delimiters<LexCtx: IsLexicalContext>() -> &'static [(TokenKind, TokenKind)] {
        match LexCtx::value() {
            {%- for context_name, context in code.scanner_contexts %}
                LexicalContext::{{ context_name }} => &[
                    {%- for open, close in context.delimiters %}
                        (TokenKind::{{ open }}, TokenKind::{{ close }}),
                    {%- endfor %}
                ],
            {%- endfor %}
        }
    }

    fn next_token<LexCtx: IsLexicalContext>(&self, input: &mut ParserContext<'_>) -> Vec<TokenKind> {
        let save = input.position();
        let mut furthest_position = input.position();
        // TODO: Replace by a SmallVec<[_; 2]> or similar
        let mut longest_tokens = vec![];

        macro_rules! longest_match {
            ($( { $kind:ident = $function:ident } )*) => {
                $(
                    if self.$function(input) && input.position() > furthest_position {
                        furthest_position = input.position();

                        longest_tokens = vec![TokenKind::$kind];
                    }
                    input.set_position(save);
                )*
            };
        }
        macro_rules! promote_keywords {
            (test $ident:ident with: $( { $kind:ident = $function:ident } )*) => {
                $(
                    let value = self.$function(input, &$ident);
                    match value {
                        _ if input.position() < furthest_position => {/* Prefix, do nothing */},
                        KeywordScan::Reserved => longest_tokens = vec![TokenKind::$kind],
                        KeywordScan::Present => longest_tokens.push(TokenKind::$kind),
                        KeywordScan::Absent => {},
                    }
                    input.set_position(save);
                )*
            };
        }

        match LexCtx::value() {
            {%- for context_name, context in code.scanner_contexts %}
                LexicalContext::{{ context_name }} => {
                    if let Some(kind) = {{ context.literal_scanner }} {
                        furthest_position = input.position();
                        longest_tokens = vec![kind];
                    }
                    input.set_position(save);

                    longest_match! {
                        {%- for name in context.compound_scanner_names %}
                            {%- if name not in context.identifier_scanners %}
                        { {{name }} = {{ name | snake_case }} }
                            {%- endif -%}
                        {%- endfor %}
                    }
                    // Make sure promotable identifiers are last so they don't grab other things
                    longest_match! {
                        {%- for name in context.identifier_scanners %}
                        { {{ name }} = {{ name | snake_case }} }
                        {%- endfor %}
                    }

                    // Attempt keyword promotion if possible
                    if longest_tokens.iter().any(|tok| [
                        {% for ident_scanner in context.identifier_scanners %}
                                TokenKind::{{ ident_scanner }},
                        {% endfor %}
                    ].contains(tok))
                    {
                        // Try fast path for atomic keywords
                        if let Some((scan, kind)) = {{ context.keyword_trie_scanner }} {
                            match scan {
                                _ if input.position() < furthest_position => {/* Prefix, do nothing */},
                                KeywordScan::Reserved => longest_tokens = vec![kind],
                                KeywordScan::Present => longest_tokens.push(kind),
                                KeywordScan::Absent => unreachable!(),
                            }
                        }

                        {%- if context.keyword_compound_scanners | length > 0 %}
                        input.set_position(save);

                        let ident_value = input.content(save.utf8..furthest_position.utf8);

                        promote_keywords! { test ident_value with:
                        {%- for keyword_name, _ in context.keyword_compound_scanners %}
                            { {{ keyword_name }} = {{ keyword_name | snake_case }} }
                        {%- endfor %}
                        }
                        {% endif %}
                    }
                },
            {%- endfor %}
        }

        match longest_tokens.as_slice() {
            [_, ..] => {
                input.set_position(furthest_position);
                longest_tokens
            },
            // Skip a character if possible and if we didn't recognize a token
            [] if input.peek().is_some() => {
                let _ = input.next();
                vec![TokenKind::SKIPPED]
            },
            [] => vec![],
        }
    }
}

#[cfg(feature = "slang_napi_interfaces")]
// NAPI-exposed functions have to accept owned values.
#[allow(clippy::needless_pass_by_value)]
#[napi(namespace = "language")]
impl Language {

    #[napi(constructor)]
    pub fn new_napi(version: String) -> std::result::Result<Self, napi::Error> {
        // IMPORTANT:
        // Make sure this does NOT panic.
        // '#[napi(catch_unwind)]' is not supported on constructors yet.
        // More Info: https://github.com/napi-rs/napi-rs/issues/1852

        let version = Version::parse(&version).map_err(|_| Error::InvalidSemanticVersion(version))?;
        Self::new(version).map_err(|e| e.into())
    }

    #[napi(getter, js_name = "version", catch_unwind)]
    pub fn version_napi(&self) -> String {
        self.version.to_string()
    }

    #[napi(js_name = "supportedVersions", catch_unwind)]
    pub fn supported_versions_napi() -> Vec<String> {
        return Self::SUPPORTED_VERSIONS.iter().map(|v| v.to_string()).collect();
    }

    #[napi(js_name = "scan", ts_return_type = "kinds.TokenKind | null", catch_unwind)]
    pub fn scan_napi(&self, lexical_context: LexicalContext, input: String) -> Vec<TokenKind> {
        self.scan(lexical_context, input.as_str())
    }

    #[napi(js_name = "parse", ts_return_type = "parse_output.ParseOutput", catch_unwind)]
    pub fn parse_napi(
        &self,
        #[napi(ts_arg_type = "kinds.RuleKind")] kind: RuleKind,
        input: String
    ) -> NAPIParseOutput {
        self.parse(kind, input.as_str()).into()
    }

}
